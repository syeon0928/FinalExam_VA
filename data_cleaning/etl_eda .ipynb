{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb0fa62e",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Import needed packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde1da8a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a0e260c",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Load all the necessary data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 809,
   "id": "9fcf3120",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Load the country-ISO code dataset\n",
    "country = pd.read_excel('../original_data/country.xlsx')\n",
    "\n",
    "# Load the population by country dataset\n",
    "pop = pd.read_csv(\"../original_data/Population.csv\")\n",
    "\n",
    "#Load the climate by country dataset\n",
    "clim = pd.read_csv(\"../original_data/Climate.csv\")\n",
    "\n",
    "#Load the currencies by country dataset\n",
    "curr = pd.read_csv(\"../original_data/Currencies.csv\")\n",
    "\n",
    "#Load the spoken languages by country dataset\n",
    "lang = pd.read_csv(\"../original_data/Languages.csv\", encoding='Latin-1'\n",
    "#Load the religion by country dataset\n",
    "rel = pd.read_csv(\"../original_data/Religion.csv\")\n",
    "\n",
    "#Load the peace index dataset\n",
    "peace = pd.read_csv(\"../original_data/Peace_Index.csv\")\n",
    "\n",
    "#Load Wef Travel Index data\n",
    "wef = pd.read_excel('../original_data/WEF_TTDI.xlsx', header=[0, 1], sheet_name='Index Performance')\n",
    "\n",
    "# Load average restaurant and accomodation cost data\n",
    "avg_rest_hot_p = pd.read_csv(\"../original_data/Avg_rest_hot_prices.csv\")\n",
    "\n",
    "# Load LGBTQ dataset\n",
    "lgbtq = pd.read_excel(\"../original_data/LGBTQ .xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d1d2100",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Get Cuisine Rank data by web scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 810,
   "outputs": [],
   "source": [
    "URL = \"https://www.tasteatlas.com/best/cuisines?fbclid=IwAR1CFukbqGEObPMECI1SdpO_dOzeMmBjhGXvRlW8GS63JwpqUAi_0QCl4nU\"\n",
    "page = requests.get(URL)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 811,
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(page.content, \"html.parser\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 812,
   "outputs": [],
   "source": [
    "# get the block that contains the ranks\n",
    "results = soup.find(id=\"BestCuisines\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 813,
   "outputs": [],
   "source": [
    "# get a list containing the names of the countries in html format\n",
    "countries = results.find_all(\"div\", class_=\"top-container\")\n",
    "# get a list containing the ratings of the countries in html format\n",
    "ratings = results.find_all(\"div\", class_=\"rating with-title\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 814,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['italy', 'greece', 'spain', 'japan', 'india', 'mexico', 'turkiye', 'USA', 'france', 'peru', 'china', 'brazil', 'portugal', 'poland', 'germany', 'indonesia', 'croatia', 'argentina', 'korea', 'vietnam', 'hungary', 'romania', 'philippines', 'iran', 'serbia', 'georgia', 'czech-republic', 'bulgaria', 'england', 'thailand', 'belgium', 'netherlands', 'austria', 'algeria', 'denmark', 'south-africa', 'syria', 'bih', 'malaysia', 'lebanon', 'ukraine', 'palestine', 'bangladesh', 'lithuania', 'taiwan', 'paraguay', 'pakistan', 'tunisia', 'uruguay', 'slovakia', 'egypt', 'singapore', 'afghanistan', 'ecuador', 'ethiopia', 'belarus', 'haiti', 'russia', 'north-macedonia', 'cuba', 'sri-lanka', 'sweden', 'chile', 'jamaica', 'slovenia', 'bolivia', 'venezuela', 'albania', 'northern-ireland', 'nigeria', 'colombia', 'finland', 'ireland', 'cyprus', 'estonia', 'new-zealand', 'guatemala', 'el-salvador', 'trinidad-and-tobago', 'wales', 'israel', 'azerbaijan', 'honduras', 'costa-rica', 'saudi-arabia', 'malta', 'switzerland', 'scotland', 'australia', 'armenia', 'iceland', 'canada', 'latvia', 'morocco', 'norway']\n"
     ]
    }
   ],
   "source": [
    "# extract text only from the countries html list\n",
    "country_ls = []\n",
    "for c in countries:\n",
    "    country_ls.append(c.find('a', href=True)['href'])\n",
    "print(country_ls)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 815,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.72, 4.69, 4.59, 4.59, 4.54, 4.53, 4.52, 4.51, 4.51, 4.51, 4.49, 4.49, 4.47, 4.44, 4.37, 4.37, 4.33, 4.33, 4.31, 4.31, 4.26, 4.25, 4.25, 4.23, 4.23, 4.23, 4.21, 4.2, 4.18, 4.16, 4.14, 4.1, 4.09, 4.07, 4.05, 4.03, 4.03, 3.99, 3.99, 3.99, 3.98, 3.98, 3.97, 3.96, 3.96, 3.96, 3.95, 3.95, 3.95, 3.94, 3.94, 3.94, 3.94, 3.93, 3.93, 3.93, 3.93, 3.92, 3.92, 3.92, 3.92, 3.91, 3.91, 3.91, 3.91, 3.91, 3.91, 3.91, 3.91, 3.91, 3.9, 3.9, 3.9, 3.9, 3.9, 3.89, 3.89, 3.88, 3.88, 3.88, 3.85, 3.85, 3.85, 3.85, 3.85, 3.84, 3.82, 3.82, 3.8, 3.8, 3.8, 3.79, 3.79, 3.69, 3.58]\n"
     ]
    }
   ],
   "source": [
    "# extract ratings only from the ratings html list\n",
    "rating_ls = []\n",
    "for rating in ratings:\n",
    "    # print(box)\n",
    "    rating_ls.append(float(rating.find(\"span\").text))\n",
    "print(rating_ls)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 816,
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 816,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if the country list and rating list length matches\n",
    "len(rating_ls)==len(country_ls)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 817,
   "outputs": [],
   "source": [
    "# Create Data Frame with extracted Data\n",
    "cuisine_rank = pd.DataFrame({'Country': country_ls, 'Ratings': rating_ls})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## EDA and Data Cleaning, Transforming"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Country - ISO CODE Dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 915,
   "outputs": [
    {
     "data": {
      "text/plain": "          Name Iso3                           Continent     SubContinent\n0        Aruba  ABW     Latin America and the Caribbean        Caribbean\n1      Andorra  ADO                              Europe  Southern Europe\n2  Afghanistan  AFG  South, East and South-Eastern Asia    Southern Asia\n3       Angola  AGO                              Africa    Middle Africa\n4      Albania  ALB                              Europe  Southern Europe",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Name</th>\n      <th>Iso3</th>\n      <th>Continent</th>\n      <th>SubContinent</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Aruba</td>\n      <td>ABW</td>\n      <td>Latin America and the Caribbean</td>\n      <td>Caribbean</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Andorra</td>\n      <td>ADO</td>\n      <td>Europe</td>\n      <td>Southern Europe</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Afghanistan</td>\n      <td>AFG</td>\n      <td>South, East and South-Eastern Asia</td>\n      <td>Southern Asia</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Angola</td>\n      <td>AGO</td>\n      <td>Africa</td>\n      <td>Middle Africa</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Albania</td>\n      <td>ALB</td>\n      <td>Europe</td>\n      <td>Southern Europe</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 915,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "country.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 914,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 329 entries, 0 to 328\n",
      "Data columns (total 4 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   Name          329 non-null    object\n",
      " 1   Iso3          329 non-null    object\n",
      " 2   Continent     329 non-null    object\n",
      " 3   SubContinent  329 non-null    object\n",
      "dtypes: object(4)\n",
      "memory usage: 10.4+ KB\n"
     ]
    }
   ],
   "source": [
    "country.info()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 858,
   "outputs": [],
   "source": [
    "country['Name'] = country['Name'].str.title()\n",
    "country['Name'] = country['Name'].str.strip()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Population dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 917,
   "outputs": [
    {
     "data": {
      "text/plain": "                       Country Country Code     Pop_2021\n0                        Aruba          ABW     107195.0\n1  Africa Eastern And Southern          AFE  694665117.0\n2                  Afghanistan          AFG   39835428.0\n3   Africa Western And Central          AFW  470898870.0\n4                       Angola          AGO   33933611.0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Country</th>\n      <th>Country Code</th>\n      <th>Pop_2021</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Aruba</td>\n      <td>ABW</td>\n      <td>107195.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Africa Eastern And Southern</td>\n      <td>AFE</td>\n      <td>694665117.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Afghanistan</td>\n      <td>AFG</td>\n      <td>39835428.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Africa Western And Central</td>\n      <td>AFW</td>\n      <td>470898870.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Angola</td>\n      <td>AGO</td>\n      <td>33933611.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 917,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pop.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 918,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 264 entries, 0 to 265\n",
      "Data columns (total 3 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   Country       264 non-null    object \n",
      " 1   Country Code  264 non-null    object \n",
      " 2   Pop_2021      264 non-null    float64\n",
      "dtypes: float64(1), object(2)\n",
      "memory usage: 8.2+ KB\n"
     ]
    }
   ],
   "source": [
    "pop.info()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 919,
   "outputs": [
    {
     "data": {
      "text/plain": "Country         0\nCountry Code    0\nPop_2021        0\ndtype: int64"
     },
     "execution_count": 919,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pop.isna().sum()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 920,
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['2021'], dtype='object')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[0;32mIn [920], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m pop[\u001B[43mpop\u001B[49m\u001B[43m[\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m2021\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m]\u001B[49m\u001B[38;5;241m.\u001B[39misnull()\u001B[38;5;241m.\u001B[39many(axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)]\n",
      "File \u001B[0;32m~/.venv/FinalExam_DS/lib/python3.9/site-packages/pandas/core/frame.py:3811\u001B[0m, in \u001B[0;36mDataFrame.__getitem__\u001B[0;34m(self, key)\u001B[0m\n\u001B[1;32m   3809\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m is_iterator(key):\n\u001B[1;32m   3810\u001B[0m         key \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(key)\n\u001B[0;32m-> 3811\u001B[0m     indexer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcolumns\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_indexer_strict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcolumns\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m[\u001B[38;5;241m1\u001B[39m]\n\u001B[1;32m   3813\u001B[0m \u001B[38;5;66;03m# take() does not accept boolean indexers\u001B[39;00m\n\u001B[1;32m   3814\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mgetattr\u001B[39m(indexer, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdtype\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m) \u001B[38;5;241m==\u001B[39m \u001B[38;5;28mbool\u001B[39m:\n",
      "File \u001B[0;32m~/.venv/FinalExam_DS/lib/python3.9/site-packages/pandas/core/indexes/base.py:6113\u001B[0m, in \u001B[0;36mIndex._get_indexer_strict\u001B[0;34m(self, key, axis_name)\u001B[0m\n\u001B[1;32m   6110\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   6111\u001B[0m     keyarr, indexer, new_indexer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reindex_non_unique(keyarr)\n\u001B[0;32m-> 6113\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_raise_if_missing\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkeyarr\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mindexer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis_name\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   6115\u001B[0m keyarr \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtake(indexer)\n\u001B[1;32m   6116\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(key, Index):\n\u001B[1;32m   6117\u001B[0m     \u001B[38;5;66;03m# GH 42790 - Preserve name from an Index\u001B[39;00m\n",
      "File \u001B[0;32m~/.venv/FinalExam_DS/lib/python3.9/site-packages/pandas/core/indexes/base.py:6173\u001B[0m, in \u001B[0;36mIndex._raise_if_missing\u001B[0;34m(self, key, indexer, axis_name)\u001B[0m\n\u001B[1;32m   6171\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m use_interval_msg:\n\u001B[1;32m   6172\u001B[0m         key \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(key)\n\u001B[0;32m-> 6173\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNone of [\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mkey\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m] are in the [\u001B[39m\u001B[38;5;132;01m{\u001B[39;00maxis_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m]\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m   6175\u001B[0m not_found \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(ensure_index(key)[missing_mask\u001B[38;5;241m.\u001B[39mnonzero()[\u001B[38;5;241m0\u001B[39m]]\u001B[38;5;241m.\u001B[39munique())\n\u001B[1;32m   6176\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mnot_found\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m not in index\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[0;31mKeyError\u001B[0m: \"None of [Index(['2021'], dtype='object')] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "pop[pop[[\"2021\"]].isnull().any(axis=1)]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Given the exploration done in the pop dataset, we can conclude that for the next step in the cleaning and transformations, we wish to keep only the \"Country Name\", \" Country Code\", and the most recent year 2021 (which we will rename to pop_2021). Moreover, to make sure that the dataset is homogeneous we will capitalize the first letter of each word in the \"Country Name\" column. We can also see that there is two null values in 2021, which will be handled."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 859,
   "outputs": [],
   "source": [
    "# Select the columns we are interest in\n",
    "pop = pop[[\"Country Name\", \"Country Code\", \"2021\"]]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 860,
   "outputs": [],
   "source": [
    "# Rename the columns\n",
    "pop = pop.rename(columns = {\"2021\": \"Pop_2021\", \"Country Name\": \"Country\"})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 861,
   "outputs": [],
   "source": [
    "# Capitalise the first letter of each word in the Country column, and remove any extra spaces\n",
    "pop[\"Country\"] = pop[\"Country\"].str.title()\n",
    "pop[\"Country\"] = pop[\"Country\"].str.strip()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 862,
   "outputs": [],
   "source": [
    "# Remove empty rows\n",
    "pop = pop.dropna()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Climate dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "clim.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "clim.info()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "clim.isna().sum()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Given the exploration done in the clim dataset, we can conclude that for the next step in the cleaning and transformations, we wish to keep all the columns, but rename them. Moreover, to make sure that the dataset is homogeneous we will capitalize the first letter of each word in the \"COUNTRY\" and \"DESCRIPTION\" column. We can also see that there is no null values, hence no handling of missing values is needed in this case."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 863,
   "outputs": [],
   "source": [
    "# Rename the columns\n",
    "clim = clim.rename(columns = {\"COUNTRY\": \"Country\", \"DESCRIPTION\": \"Climate\"})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 864,
   "outputs": [],
   "source": [
    "# Capitalise the first letter of each word in the Country and Climate column, and remove any extra spaces in the Country column\n",
    "clim[\"Country\"] = clim[\"Country\"].str.title()\n",
    "clim[\"Country\"] = clim[\"Country\"].str.strip()\n",
    "clim[\"Climate\"] = clim[\"Climate\"].str.title()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 865,
   "outputs": [],
   "source": [
    "# Set a new column that classifies climates \n",
    "conditions = [(clim[\"Climate\"].str.contains(\"Tropical|Arid|Semiarid|Desert\")),\n",
    "              (clim[\"Climate\"].str.contains(\"Temperate|Continental|Hot Summers And Cold Winters\" )), \n",
    "              (clim[\"Climate\"].str.contains(\"Mediterranean|Subtropical\")),\n",
    "              (clim[\"Climate\"].str.contains(\"Highland\")), \n",
    "              (clim[\"Climate\"].str.contains(\"Polar|Antarctic\")),  \n",
    "              (clim[\"Climate\"].str.contains(\"Equatorial\"))]\n",
    "\n",
    "choices = [\"Tropical\", \"Temperate\", \"Subtropical\", \"Highland\", \"Polar\", \"Equatorial\" ]\n",
    "clim[\"Climate Zone\"] = np.select(conditions, choices, default = \"\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Currency dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "curr.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "curr.info()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "curr.isna().sum()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "curr[curr[[\"AlphabeticCode\"]].isnull().any(axis=1)]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "curr[curr[[\"WithdrawalDate\"]].notnull().any(axis=1)]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Given the exploration done in the curr dataset, we can conclude that for the next step in the cleaning and transformations, we wish to keep only the \"Entity\", \"Currency\", and \"AlphabeticCode\" columns, but rename them. Moreover, to make sure that the dataset is homogeneous we will capitalize the first letter of each word in the \"Entity\" and \"Currency\" column. We can also see that there is three null values in the \"AlphabeticCode\" column, which will be handled. In addition, there are a number of currencies which are no longer used, we will them subset this dataset to only contain currently accepted currencies."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 866,
   "outputs": [],
   "source": [
    "# Keep only the rows without a withdrawal date\n",
    "curr = curr[curr[[\"WithdrawalDate\"]].isnull().any(axis=1)]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 867,
   "outputs": [],
   "source": [
    "# Select the columns to keep\n",
    "curr = curr[[\"Entity\", \"Currency\", \"AlphabeticCode\"]]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 868,
   "outputs": [],
   "source": [
    "# Rename the columns\n",
    "curr = curr.rename(columns = {\"Entity\": \"Country\", \"AlphabeticCode\": \"Currency Code\"})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 869,
   "outputs": [],
   "source": [
    "# Capitalise the first letter of each word in the Country and Currency columns, and remove any extra spaces in the country column. Remove any text after \"(\" in the country column.\n",
    "curr[\"Country\"] = curr[\"Country\"].str.title()\n",
    "curr[\"Country\"] = curr['Country'].str.partition(\"(\")[0]\n",
    "curr[\"Country\"] = curr[\"Country\"].str.strip()\n",
    "curr[\"Currency\"] = curr[\"Currency\"].str.title()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 870,
   "outputs": [],
   "source": [
    "# Fill the null values with Non Applicable\n",
    "curr[\"Currency Code\"].fillna(\"Non Applicable\", inplace= True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Language dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "lang.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "lang.info()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "lang.isna().sum()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Given the exploration done in the lang dataset, we can conclude that for the next step in the cleaning and transformations, we wish to keep all the columns, but rename them. Moreover, to make sure that the dataset is homogeneous we will capitalize the first letter of each word in the \"Country\" and \"Language Spoken\" column. We can also see that there is no null values, hence no handling of missing values is needed in this case. In addition, we can see that the languages spoken includes more than the official languages, in the cleaning we will strive to only keep the official languages."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 871,
   "outputs": [],
   "source": [
    "# Rename the columns\n",
    "lang = lang.rename(columns = {\"Languages Spoken\": \"Official Language\"})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 872,
   "outputs": [],
   "source": [
    "# Capitalise the first letter of each word in the Country and Official Language columns\n",
    "lang[\"Country\"] = lang[\"Country\"].str.title()\n",
    "lang[\"Country\"] = lang[\"Country\"].str.strip()\n",
    "lang[\"Official Language\"] = lang[\"Official Language\"].str.title()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 873,
   "outputs": [],
   "source": [
    "def language_cleaning(lan: str):\n",
    "    \"\"\" This function is to clean the official languages, the rule is\n",
    "    - If the official contains '(official)' in the text, adopt languages that come before '(official)\n",
    "    - Otherwise take only first language\"\"\"\n",
    "\n",
    "    # replace 'and' to comma\n",
    "    # delete numbers and percentage\n",
    "    lan = lan.replace(' And ', ', ')\n",
    "    lan = re.sub(\"[\\d%.]\", \"\", lan)\n",
    "\n",
    "    # first if the text contains 'official', we are going to keep all the official\n",
    "    if 'Official' in lan:\n",
    "        lan = lan.partition(\"(\")[0].strip()\n",
    "\n",
    "    # otherwise, we are going to keep first one as a main language spoken\n",
    "    else:\n",
    "        lan = lan.partition(\",\")[0].strip()\n",
    "\n",
    "    return lan"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 874,
   "outputs": [],
   "source": [
    "# apply language cleaning function to the 'languages Spoken' column\n",
    "lang['Official Language'] = lang['Official Language'].apply(language_cleaning)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 875,
   "outputs": [
    {
     "data": {
      "text/plain": "                             Country     Official Language\n0                        Afghanistan  Dari Persian, Pashtu\n1                            Albania              Albanian\n2                            Algeria                Arabic\n3                            Andorra              Catalã¡N\n4                             Angola            Portuguese\n..                               ...                   ...\n193                          Vietnam            Vietnamese\n194  Western Sahara (Proposed State)      Hassaniya Arabic\n195                            Yemen                Arabic\n196                           Zambia               English\n197                         Zimbabwe               English\n\n[198 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Country</th>\n      <th>Official Language</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Afghanistan</td>\n      <td>Dari Persian, Pashtu</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Albania</td>\n      <td>Albanian</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Algeria</td>\n      <td>Arabic</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Andorra</td>\n      <td>Catalã¡N</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Angola</td>\n      <td>Portuguese</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>193</th>\n      <td>Vietnam</td>\n      <td>Vietnamese</td>\n    </tr>\n    <tr>\n      <th>194</th>\n      <td>Western Sahara (Proposed State)</td>\n      <td>Hassaniya Arabic</td>\n    </tr>\n    <tr>\n      <th>195</th>\n      <td>Yemen</td>\n      <td>Arabic</td>\n    </tr>\n    <tr>\n      <th>196</th>\n      <td>Zambia</td>\n      <td>English</td>\n    </tr>\n    <tr>\n      <th>197</th>\n      <td>Zimbabwe</td>\n      <td>English</td>\n    </tr>\n  </tbody>\n</table>\n<p>198 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 875,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lang"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Religion dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rel.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rel.info()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rel.isna().sum()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rel[rel[[\"Religion\"]].isnull().any(axis=1)]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rel[rel[[\"Area\"]].isnull().any(axis=1)]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rel[rel[[\"Sex\"]].isnull().any(axis=1)]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Given the exploration done in the rel dataset, we can conclude that for the next step in the cleaning and transformations, we wish to keep the \"Country or Area\" and \"Religion\" columns but rename them. Moreover, to make sure that the dataset is homogeneous we will capitalize the first letter of each word in the \"Country or Area\" column. We can also see that there is multiple null values, that arise due to the existing footnotes at the end of the document, which will be dealt with. In addition, we can see that for each country there is the listing of all the religions present in the country. As we only wish to keep the main one the others will be removed."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 876,
   "outputs": [],
   "source": [
    "# Remove the footnote rows, which is where the Religion column \n",
    "rel = rel[rel[[\"Religion\"]].notna().any(axis=1)]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 877,
   "outputs": [],
   "source": [
    "# Remove the rows with the total number of religious people. Also remove the other, not stated, and refused to answer religions\n",
    "rel = rel[rel[\"Religion\"].str.contains(\"Total|Other|Not Stated|Refused to answer\") == False]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 878,
   "outputs": [],
   "source": [
    "# Keep the data from the most recent year for each country\n",
    "rel = rel.sort_values(by=[\"Country or Area\", \"Year\"])\n",
    "rel = rel.drop_duplicates(subset=['Country or Area', \"Religion\"], keep='last')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 879,
   "outputs": [],
   "source": [
    "# Keep the rows with the highest value, meaning the main religion of each country\n",
    "rel = rel.sort_values(by=[\"Country or Area\", \"Value\"])\n",
    "rel = rel.drop_duplicates(subset=['Country or Area'], keep='last')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 880,
   "outputs": [],
   "source": [
    "# Select the columns to keep\n",
    "rel = rel[[\"Country or Area\", \"Religion\"]]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 881,
   "outputs": [],
   "source": [
    "# Rename the columns\n",
    "rel = rel.rename(columns = {\"Country or Area\": \"Country\", \"Religion\": \"Main Religion\"})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 882,
   "outputs": [],
   "source": [
    "# Capitalise the first letter of each word in the Country and religion, and remove any extra spaces in the country column.\n",
    "rel[\"Country\"] = rel[\"Country\"].str.title()\n",
    "rel[\"Country\"] = rel[\"Country\"].str.strip()\n",
    "rel[\"Main Religion\"] = rel[\"Main Religion\"].str.title()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Peace index dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "peace.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "peace.info()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "peace.isna().sum()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "peace[peace[[\"COUNTRY\"]].isnull().any(axis=1)]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Given the exploration done in the peace dataset, we can conclude that for the next step in the cleaning and transformations, we wish to keep the \"RANK\", and \"COUNTRY\" columns, but rename them. Moreover, to make sure that the dataset is homogeneous we will capitalize the first letter of each word in the \"COUNTRY\" column. We can also see that there is multiple null values, that arise due to the existing of completely empty rows, which will be dealt with."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 883,
   "outputs": [],
   "source": [
    "# Select the columns to keep\n",
    "peace = peace[[\"RANK\", \"COUNTRY\"]]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 884,
   "outputs": [],
   "source": [
    "# Rename the columns\n",
    "peace = peace.rename(columns = {\"RANK\": \"Rank\", \"COUNTRY\": \"Country\"})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 885,
   "outputs": [],
   "source": [
    "# Capitalise the first letter of each word in the Country column\n",
    "peace[\"Country\"] = peace[\"Country\"].str.title()\n",
    "peace[\"Country\"] = peace[\"Country\"].str.strip()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 886,
   "outputs": [],
   "source": [
    "# Drop null rows\n",
    "peace = peace.dropna()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### WEF Dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# to flatten the double header from excel\n",
    "wef.columns=wef.columns.to_flat_index()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "wef.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "wef.info()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "wef.isna().sum()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Among 143 columns we have in dataset, we will choose relevant columns and drop all the others. We found we have no null data in the dataset. Moreover, as the dataset have ISO code itself, there is no further cleaning needed for the country name."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 887,
   "outputs": [],
   "source": [
    "# Rename columns\n",
    "wef.rename(columns = {('Unnamed: 0_level_0', 'ISO Code'):'ISO Code',\n",
    "                      ('Unnamed: 1_level_0', 'Economy'):'Country',\n",
    "                      ('Unnamed: 2_level_0', 'Region'):'Continent',\n",
    "                      ('Unnamed: 3_level_0', 'Sub Region'):'Sub Continent',\n",
    "                      ('Unnamed: 4_level_0', 'Income Group'):'Income Group'\n",
    "                      }, inplace = True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 888,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 ISO Code\n",
      "1 Country\n",
      "2 Continent\n",
      "3 Sub Continent\n",
      "4 Income Group\n",
      "5 ('Travel & Tourism Development Index ', '2019 Value')\n",
      "6 ('Travel & Tourism Development Index ', '2019 Rank')\n",
      "7 ('Travel & Tourism Development Index ', '2021 Value')\n",
      "8 ('Travel & Tourism Development Index ', '2021 Rank')\n",
      "9 ('Travel & Tourism Development Index ', '% Dif Score')\n",
      "10 ('Travel & Tourism Development Index ', 'Rank Change')\n",
      "11 ('Enabling Environment subindex', '2019 Value')\n",
      "12 ('Enabling Environment subindex', '2019 Rank')\n",
      "13 ('Enabling Environment subindex', '2021 Value')\n",
      "14 ('Enabling Environment subindex', '2021 Rank')\n",
      "15 ('Enabling Environment subindex', '% Dif Score')\n",
      "16 ('Enabling Environment subindex', 'Rank Change')\n",
      "17 ('Travel and Tourism Policy and Enabling\\nConditions subindex', '2019 Value')\n",
      "18 ('Travel and Tourism Policy and Enabling\\nConditions subindex', '2019 Rank')\n",
      "19 ('Travel and Tourism Policy and Enabling\\nConditions subindex', '2021 Value')\n",
      "20 ('Travel and Tourism Policy and Enabling\\nConditions subindex', '2021 Rank')\n",
      "21 ('Travel and Tourism Policy and Enabling\\nConditions subindex', '% Dif Score')\n",
      "22 ('Travel and Tourism Policy and Enabling\\nConditions subindex', 'Rank Change')\n",
      "23 ('Infrastructure subindex', '2019 Value')\n",
      "24 ('Infrastructure subindex', '2019 Rank')\n",
      "25 ('Infrastructure subindex', '2021 Value')\n",
      "26 ('Infrastructure subindex', '2021 Rank')\n",
      "27 ('Infrastructure subindex', '% Dif Score')\n",
      "28 ('Infrastructure subindex', 'Rank Change')\n",
      "29 ('Travel and Tourism Demand Drivers\\nsubindex', '2019 Value')\n",
      "30 ('Travel and Tourism Demand Drivers\\nsubindex', '2019 Rank')\n",
      "31 ('Travel and Tourism Demand Drivers\\nsubindex', '2021 Value')\n",
      "32 ('Travel and Tourism Demand Drivers\\nsubindex', '2021 Rank')\n",
      "33 ('Travel and Tourism Demand Drivers\\nsubindex', '% Dif Score')\n",
      "34 ('Travel and Tourism Demand Drivers\\nsubindex', 'Rank Change')\n",
      "35 ('Travel and Tourism Sustainability subindex', '2019 Value')\n",
      "36 ('Travel and Tourism Sustainability subindex', '2019 Rank')\n",
      "37 ('Travel and Tourism Sustainability subindex', '2021 Value')\n",
      "38 ('Travel and Tourism Sustainability subindex', '2021 Rank')\n",
      "39 ('Travel and Tourism Sustainability subindex', '% Dif Score')\n",
      "40 ('Travel and Tourism Sustainability subindex', 'Rank Change')\n",
      "41 ('Business Environment pillar', '2019 Value')\n",
      "42 ('Business Environment pillar', '2019 Rank')\n",
      "43 ('Business Environment pillar', '2021 Value')\n",
      "44 ('Business Environment pillar', '2021 Rank')\n",
      "45 ('Business Environment pillar', '% Dif Score')\n",
      "46 ('Business Environment pillar', 'Rank Change')\n",
      "47 ('Safety and Security pillar', '2019 Value')\n",
      "48 ('Safety and Security pillar', '2019 Rank')\n",
      "49 ('Safety and Security pillar', '2021 Value')\n",
      "50 ('Safety and Security pillar', '2021 Rank')\n",
      "51 ('Safety and Security pillar', '% Dif Score')\n",
      "52 ('Safety and Security pillar', 'Rank Change')\n",
      "53 ('Health and Hygiene pillar', '2019 Value')\n",
      "54 ('Health and Hygiene pillar', '2019 Rank')\n",
      "55 ('Health and Hygiene pillar', '2021 Value')\n",
      "56 ('Health and Hygiene pillar', '2021 Rank')\n",
      "57 ('Health and Hygiene pillar', '% Dif Score')\n",
      "58 ('Health and Hygiene pillar', 'Rank Change')\n",
      "59 ('Human Resources and Labour Market pillar', '2019 Value')\n",
      "60 ('Human Resources and Labour Market pillar', '2019 Rank')\n",
      "61 ('Human Resources and Labour Market pillar', '2021 Value')\n",
      "62 ('Human Resources and Labour Market pillar', '2021 Rank')\n",
      "63 ('Human Resources and Labour Market pillar', '% Dif Score')\n",
      "64 ('Human Resources and Labour Market pillar', 'Rank Change')\n",
      "65 ('ICT Readiness pillar', '2019 Value')\n",
      "66 ('ICT Readiness pillar', '2019 Rank')\n",
      "67 ('ICT Readiness pillar', '2021 Value')\n",
      "68 ('ICT Readiness pillar', '2021 Rank')\n",
      "69 ('ICT Readiness pillar', '% Dif Score')\n",
      "70 ('ICT Readiness pillar', 'Rank Change')\n",
      "71 ('Prioritization of Travel & Tourism pillar', '2019 Value')\n",
      "72 ('Prioritization of Travel & Tourism pillar', '2019 Rank')\n",
      "73 ('Prioritization of Travel & Tourism pillar', '2021 Value')\n",
      "74 ('Prioritization of Travel & Tourism pillar', '2021 Rank')\n",
      "75 ('Prioritization of Travel & Tourism pillar', '% Dif Score')\n",
      "76 ('Prioritization of Travel & Tourism pillar', 'Rank Change')\n",
      "77 ('International Openness pillar', '2019 Value')\n",
      "78 ('International Openness pillar', '2019 Rank')\n",
      "79 ('International Openness pillar', '2021 Value')\n",
      "80 ('International Openness pillar', '2021 Rank')\n",
      "81 ('International Openness pillar', '% Dif Score')\n",
      "82 ('International Openness pillar', 'Rank Change')\n",
      "83 ('Price competitiveness pillar', '2019 Value')\n",
      "84 ('Price competitiveness pillar', '2019 Rank')\n",
      "85 ('Price competitiveness pillar', '2021 Value')\n",
      "86 ('Price competitiveness pillar', '2021 Rank')\n",
      "87 ('Price competitiveness pillar', '% Dif Score')\n",
      "88 ('Price competitiveness pillar', 'Rank Change')\n",
      "89 ('Air Transport Infrastructure pillar', '2019 Value')\n",
      "90 ('Air Transport Infrastructure pillar', '2019 Rank')\n",
      "91 ('Air Transport Infrastructure pillar', '2021 Value')\n",
      "92 ('Air Transport Infrastructure pillar', '2021 Rank')\n",
      "93 ('Air Transport Infrastructure pillar', '% Dif Score')\n",
      "94 ('Air Transport Infrastructure pillar', 'Rank Change')\n",
      "95 ('Ground and Port Infrastructure pillar', '2019 Value')\n",
      "96 ('Ground and Port Infrastructure pillar', '2019 Rank')\n",
      "97 ('Ground and Port Infrastructure pillar', '2021 Value')\n",
      "98 ('Ground and Port Infrastructure pillar', '2021 Rank')\n",
      "99 ('Ground and Port Infrastructure pillar', '% Dif Score')\n",
      "100 ('Ground and Port Infrastructure pillar', 'Rank Change')\n",
      "101 ('Tourist Service Infrastructure pillar', '2019 Value')\n",
      "102 ('Tourist Service Infrastructure pillar', '2019 Rank')\n",
      "103 ('Tourist Service Infrastructure pillar', '2021 Value')\n",
      "104 ('Tourist Service Infrastructure pillar', '2021 Rank')\n",
      "105 ('Tourist Service Infrastructure pillar', '% Dif Score')\n",
      "106 ('Tourist Service Infrastructure pillar', 'Rank Change')\n",
      "107 ('Natural Resources pillar', '2019 Value')\n",
      "108 ('Natural Resources pillar', '2019 Rank')\n",
      "109 ('Natural Resources pillar', '2021 Value')\n",
      "110 ('Natural Resources pillar', '2021 Rank')\n",
      "111 ('Natural Resources pillar', '% Dif Score')\n",
      "112 ('Natural Resources pillar', 'Rank Change')\n",
      "113 ('Cultural Resources pillar', '2019 Value')\n",
      "114 ('Cultural Resources pillar', '2019 Rank')\n",
      "115 ('Cultural Resources pillar', '2021 Value')\n",
      "116 ('Cultural Resources pillar', '2021 Rank')\n",
      "117 ('Cultural Resources pillar', '% Dif Score')\n",
      "118 ('Cultural Resources pillar', 'Rank Change')\n",
      "119 ('Non-Leisure Resources pillar', '2019 Value')\n",
      "120 ('Non-Leisure Resources pillar', '2019 Rank')\n",
      "121 ('Non-Leisure Resources pillar', '2021 Value')\n",
      "122 ('Non-Leisure Resources pillar', '2021 Rank')\n",
      "123 ('Non-Leisure Resources pillar', '% Dif Score')\n",
      "124 ('Non-Leisure Resources pillar', 'Rank Change')\n",
      "125 ('Environmental Sustainability pillar', '2019 Value')\n",
      "126 ('Environmental Sustainability pillar', '2019 Rank')\n",
      "127 ('Environmental Sustainability pillar', '2021 Value')\n",
      "128 ('Environmental Sustainability pillar', '2021 Rank')\n",
      "129 ('Environmental Sustainability pillar', '% Dif Score')\n",
      "130 ('Environmental Sustainability pillar', 'Rank Change')\n",
      "131 ('Socioeconomic Resilience & Conditions pillar', '2019 Value')\n",
      "132 ('Socioeconomic Resilience & Conditions pillar', '2019 Rank')\n",
      "133 ('Socioeconomic Resilience & Conditions pillar', '2021 Value')\n",
      "134 ('Socioeconomic Resilience & Conditions pillar', '2021 Rank')\n",
      "135 ('Socioeconomic Resilience & Conditions pillar', '% Dif Score')\n",
      "136 ('Socioeconomic Resilience & Conditions pillar', 'Rank Change')\n",
      "137 ('T&T Demand Pressure & Impact pillar', '2019 Value')\n",
      "138 ('T&T Demand Pressure & Impact pillar', '2019 Rank')\n",
      "139 ('T&T Demand Pressure & Impact pillar', '2021 Value')\n",
      "140 ('T&T Demand Pressure & Impact pillar', '2021 Rank')\n",
      "141 ('T&T Demand Pressure & Impact pillar', '% Dif Score')\n",
      "142 ('T&T Demand Pressure & Impact pillar', 'Rank Change')\n"
     ]
    }
   ],
   "source": [
    "# To check the index of the columns that we wish to drop\n",
    "for i, col in enumerate(wef.columns):\n",
    "    print(i, col)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 889,
   "outputs": [
    {
     "data": {
      "text/plain": "Index([                                           'ISO Code',\n                                                   'Country',\n                                                 'Continent',\n                                             'Sub Continent',\n                                              'Income Group',\n       ('Travel & Tourism Development Index ', '2021 Value'),\n        ('Travel & Tourism Development Index ', '2021 Rank'),\n                   ('Infrastructure subindex', '2021 Value'),\n                    ('Infrastructure subindex', '2021 Rank'),\n                ('Safety and Security pillar', '2021 Value'),\n                 ('Safety and Security pillar', '2021 Rank'),\n                 ('Health and Hygiene pillar', '2021 Value'),\n                  ('Health and Hygiene pillar', '2021 Rank'),\n             ('International Openness pillar', '2021 Value'),\n              ('International Openness pillar', '2021 Rank'),\n              ('Price competitiveness pillar', '2021 Value'),\n               ('Price competitiveness pillar', '2021 Rank'),\n                  ('Natural Resources pillar', '2021 Value'),\n                   ('Natural Resources pillar', '2021 Rank'),\n                 ('Cultural Resources pillar', '2021 Value'),\n                  ('Cultural Resources pillar', '2021 Rank'),\n       ('Environmental Sustainability pillar', '2021 Value'),\n        ('Environmental Sustainability pillar', '2021 Rank'),\n       ('T&T Demand Pressure & Impact pillar', '2021 Value'),\n        ('T&T Demand Pressure & Impact pillar', '2021 Rank')],\n      dtype='object')"
     },
     "execution_count": 889,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop columns from the behind to prevent index changing\n",
    "wef = wef.iloc[:, [0,1,2,3,4,7,8,25,26,49,50,55,56,79,80,85,86,109,110,115,116,127,128,139,140]]\n",
    "wef.columns"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Set new columns that classify each index into Very good, Good, Limited"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 890,
   "outputs": [],
   "source": [
    "# Infrastructure subindex\n",
    "conditions = [(wef[ ('Infrastructure subindex', '2021 Rank')] <= 40), (wef[('Infrastructure subindex', '2021 Rank')] >= 80)]\n",
    "choices = [\"Very good\", \"Limited\"]\n",
    "wef[\"Infrastructure subindex, classification\"] = np.select(conditions, choices, default = \"Good\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 891,
   "outputs": [],
   "source": [
    "# Safety and Security pillar\n",
    "conditions = [(wef[('Safety and Security pillar', '2021 Rank')] <= 40), (wef[ ('Safety and Security pillar', '2021 Rank')] >= 80)]\n",
    "choices = [\"Very good\", \"Limited\"]\n",
    "wef[\"Safety and Security, Classification\"] = np.select(conditions, choices, default = \"Good\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 892,
   "outputs": [],
   "source": [
    "# Health and Hygiene pillar\n",
    "conditions = [(wef[('Health and Hygiene pillar', '2021 Rank')] <= 40), (wef[('Health and Hygiene pillar', '2021 Rank')] >= 80)]\n",
    "choices = [\"Very good\", \"Limited\"]\n",
    "wef[\"Health and Hygiene, Classification\"] = np.select(conditions, choices, default = \"Good\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 893,
   "outputs": [],
   "source": [
    "# International Openness pillar\n",
    "conditions = [(wef[('International Openness pillar', '2021 Rank')] <= 40), (wef[('International Openness pillar', '2021 Rank')] >= 80)]\n",
    "choices = [\"Very good\", \"Limited\"]\n",
    "wef[\"International Openess, Classification\"] = np.select(conditions, choices, default = \"Good\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 894,
   "outputs": [],
   "source": [
    "# Price competitiveness pillar\n",
    "conditions = [(wef[('Price competitiveness pillar', '2021 Rank')] <= 40), (wef[ ('Price competitiveness pillar', '2021 Rank')] >= 80)]\n",
    "choices = [\"Very good\", \"Limited\"]\n",
    "wef[\"Price competitiveness, Classification\"] = np.select(conditions, choices, default = \"Good\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 895,
   "outputs": [],
   "source": [
    "# Natural Resources pillar\n",
    "conditions = [(wef[('Natural Resources pillar', '2021 Rank')] <= 40), (wef[('Natural Resources pillar', '2021 Rank')] >= 80)]\n",
    "choices = [\"Very good\", \"Limited\"]\n",
    "wef[\"Natural Resources, Classification\"] = np.select(conditions, choices, default = \"Good\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 896,
   "outputs": [],
   "source": [
    "# Cultural Resources pillar\n",
    "conditions = [(wef[('Cultural Resources pillar', '2021 Rank')] <= 40), (wef[('Cultural Resources pillar', '2021 Rank')] >= 80)]\n",
    "choices = [\"Very good\", \"Limited\"]\n",
    "wef[\"Cultural Resources, Classification\"] = np.select(conditions, choices, default = \"Good\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 897,
   "outputs": [],
   "source": [
    "# Environmental Sustainability pillar\n",
    "conditions = [(wef[('Environmental Sustainability pillar', '2021 Rank')] <= 40), (wef[('Environmental Sustainability pillar', '2021 Rank')] >= 80)]\n",
    "choices = [\"Very good\", \"Limited\"]\n",
    "wef[\"Environmental Sustainability, Classification\"] = np.select(conditions, choices, default = \"Good\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 898,
   "outputs": [],
   "source": [
    "# T&T Demand Pressure & Impact pillar\n",
    "conditions = [(wef[('T&T Demand Pressure & Impact pillar', '2021 Rank')] <= 40), (wef[('T&T Demand Pressure & Impact pillar', '2021 Rank')] >= 80)]\n",
    "choices = [\"Very good\", \"Limited\"]\n",
    "wef[\"T&T Demand Pressure & Impact, Classification\"] = np.select(conditions, choices, default = \"Good\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Average Restaurant and Accomodation Cost Dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "avg_rest_hot_p.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "avg_rest_hot_p.info()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "avg_rest_hot_p.isna().sum()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "avg_rest_hot_p[avg_rest_hot_p[[\"Country Name\"]].isnull().any(axis=1)]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "avg_rest_hot_p[avg_rest_hot_p[[\"Country Code\"]].isnull().any(axis=1)]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Given the exploration done in the avg_rest_hot_p dataset, we can conclude that for the next step in the cleaning and transformations, we wish to keep only the \"Country Name\", \" Country Code\", and the \"2017 [YR2017]\" columns, but we will rename them. Moreover, to make sure that the dataset is homogeneous we will capitalize the first letter of each word in the \"Country Name\" column. We can also see that there is 5 null values, which arise due to empty rows and footnotes, these will be handled accordingly. Additionally, we can see that some countries in the average price have \"..\" instead of being null, which will be solved."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 899,
   "outputs": [],
   "source": [
    "# Select the columns we are interest in\n",
    "avg_rest_hot_p = avg_rest_hot_p[[\"Country Name\", \"Country Code\", \"2017 [YR2017]\"]]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 900,
   "outputs": [],
   "source": [
    "# Rename the columns\n",
    "avg_rest_hot_p = avg_rest_hot_p.rename(columns = {\"Country Name\": \"Country\", \"2017 [YR2017]\": \"Average Hotel and Restaurant Cost\"})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 901,
   "outputs": [],
   "source": [
    "# Capitalise the first letter of each word in the Country column, and remove any extra spaces\n",
    "avg_rest_hot_p[\"Country\"] = avg_rest_hot_p[\"Country\"].str.title()\n",
    "avg_rest_hot_p[\"Country\"] = avg_rest_hot_p[\"Country\"].str.strip()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 902,
   "outputs": [],
   "source": [
    "# Substitute \"..\" for null value\n",
    "avg_rest_hot_p[\"Average Hotel and Restaurant Cost\"] = avg_rest_hot_p[\"Average Hotel and Restaurant Cost\"].replace(\"..\",\"\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 903,
   "outputs": [],
   "source": [
    "# Remove empty rows\n",
    "avg_rest_hot_p = avg_rest_hot_p.dropna()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 904,
   "id": "0ae68ea2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Remove empty rows\n",
    "avg_rest_hot_p = avg_rest_hot_p.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 905,
   "id": "ddad2ee9",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Convert the column from string to numeric value\n",
    "avg_rest_hot_p[\"Average Hotel and Restaurant Cost\"] = pd.to_numeric(avg_rest_hot_p[\"Average Hotel and Restaurant Cost\"], errors = \"coerce\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 906,
   "id": "9779e091",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Round the numbers to two decimal points\n",
    "avg_rest_hot_p[\"Average Hotel and Restaurant Cost\"] = avg_rest_hot_p[\"Average Hotel and Restaurant Cost\"].round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 907,
   "id": "3da76cbd",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Set a new column that classifies countries into budget travel, comfortable travel and luxury travel\n",
    "conditions = [(avg_rest_hot_p[\"Average Hotel and Restaurant Cost\"] <= 70), ((avg_rest_hot_p[\"Average Hotel and Restaurant Cost\"] > 70) & (avg_rest_hot_p[\"Average Hotel and Restaurant Cost\"] <= 150)), (avg_rest_hot_p[\"Average Hotel and Restaurant Cost\"] > 150)]\n",
    "choices = [\"Budget Traveler\", \"Comfort traveler\", \"Luxury Travel\"]\n",
    "avg_rest_hot_p[\"Type Traveler\"] = np.select(conditions, choices, default = \"Non Applicable\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "lgbtq.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "lgbtq.info()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "id": "fde0129b",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### LGBTQ Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 908,
   "id": "2b5d3f24",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "lgbtq['COUNTRY'] = lgbtq['COUNTRY'].str.title()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 911,
   "outputs": [
    {
     "data": {
      "text/plain": "  Country  Ratings\n0   italy     4.72\n1  greece     4.69\n2   spain     4.59\n3   japan     4.59\n4   india     4.54",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Country</th>\n      <th>Ratings</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>italy</td>\n      <td>4.72</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>greece</td>\n      <td>4.69</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>spain</td>\n      <td>4.59</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>japan</td>\n      <td>4.59</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>india</td>\n      <td>4.54</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 911,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cuisine_rank.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 912,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 95 entries, 0 to 94\n",
      "Data columns (total 2 columns):\n",
      " #   Column   Non-Null Count  Dtype  \n",
      "---  ------   --------------  -----  \n",
      " 0   Country  95 non-null     object \n",
      " 1   Ratings  95 non-null     float64\n",
      "dtypes: float64(1), object(1)\n",
      "memory usage: 1.6+ KB\n"
     ]
    }
   ],
   "source": [
    "cuisine_rank.info()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "id": "41cbc4b3",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Cuisine Rank Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 913,
   "id": "19e1e80c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "    Country  Ratings\n0     italy     4.72\n1    greece     4.69\n2     spain     4.59\n3     japan     4.59\n4     india     4.54\n..      ...      ...\n90  iceland     3.80\n91   canada     3.79\n92   latvia     3.79\n93  morocco     3.69\n94   norway     3.58\n\n[95 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Country</th>\n      <th>Ratings</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>italy</td>\n      <td>4.72</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>greece</td>\n      <td>4.69</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>spain</td>\n      <td>4.59</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>japan</td>\n      <td>4.59</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>india</td>\n      <td>4.54</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>90</th>\n      <td>iceland</td>\n      <td>3.80</td>\n    </tr>\n    <tr>\n      <th>91</th>\n      <td>canada</td>\n      <td>3.79</td>\n    </tr>\n    <tr>\n      <th>92</th>\n      <td>latvia</td>\n      <td>3.79</td>\n    </tr>\n    <tr>\n      <th>93</th>\n      <td>morocco</td>\n      <td>3.69</td>\n    </tr>\n    <tr>\n      <th>94</th>\n      <td>norway</td>\n      <td>3.58</td>\n    </tr>\n  </tbody>\n</table>\n<p>95 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 913,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cuisine_rank['Country'] = cuisine_rank['Country'].str.replace('-', ' ')\n",
    "cuisine_rank['Country'] = cuisine_rank['Country'].str.title()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 910,
   "id": "cf3db153",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (861960806.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;36m  Cell \u001B[0;32mIn [910], line 2\u001B[0;36m\u001B[0m\n\u001B[0;31m    We will join all datasets with country data, so that all dataset can have ISO Code.\u001B[0m\n\u001B[0m       ^\u001B[0m\n\u001B[0;31mSyntaxError\u001B[0m\u001B[0;31m:\u001B[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "cuisine_rank"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa1e1a8",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Airport distance - country"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55532386",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Check climate - country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4570a4da",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "clim = clim.merge(country[['Name','Iso3']], how='left', left_on='Country', right_on='Name')\n",
    "clim.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7166ab36",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# check the countries that are not merged\n",
    "clim[clim['Name'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f8e7f22",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# drop the countries that are not merged\n",
    "clim = clim.dropna(subset=['Name'])\n",
    "# drop the merged country name column to avoid repetition\n",
    "clim = clim.drop(['Name'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1865fb87",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "clim.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43cfe299",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Check Currency - Country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f57ec348",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "curr = curr.merge(country[['Name','Iso3']], how='left', left_on='Country', right_on='Name')\n",
    "curr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f0a70a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "curr[curr['Name'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3acb4695",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "curr = curr.dropna(subset= ['Name'])\n",
    "curr = curr.drop(['Name'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f423980",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Check language - country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9037d63",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "lang = lang.merge(country[['Name','Iso3']], how='left', left_on='Country', right_on='Name')\n",
    "lang.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47abd5fa",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "lang[lang['Name'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd732fc",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "lang = lang.dropna(subset=['Name'])\n",
    "lang = lang.drop(['Name'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f327941",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Check peace - country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2ac07f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "peace=peace.merge(country[['Name','Iso3']], how='left', left_on='Country', right_on='Name')\n",
    "peace.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4519886",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "peace[peace['Name'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "926e72ca",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "peace=peace.dropna(subset=['Name'])\n",
    "peace = peace.drop(['Name'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04a1eb5f",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Check population - country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1858406c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pop=pop.merge(country[['Name','Iso3']], how='left', left_on='Country', right_on='Name')\n",
    "pop.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54dc106a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pop[pop['Name'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "004dd4dc",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pop = pop.dropna(subset=['Name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b51837",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# drop both country name and iso code from the merged dataset, as population data already contains ISO code\n",
    "pop = pop.drop(['Name', 'Iso3'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e9801b",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Check Religion - country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa272d7",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "rel=rel.merge(country[['Name','Iso3']], how='left', left_on='Country', right_on='Name')\n",
    "rel.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89692c3c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "rel[rel['Name'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d798242d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "rel = rel.dropna(subset=['Name'])\n",
    "rel = rel.drop(['Name'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f75f68f9",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Check Average Restaurant and Accomodation Cost - ISO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d23bb84",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "avg_rest_hot_p = avg_rest_hot_p.merge(country[['Name','Iso3']], how='left', left_on='Country Code', right_on='Iso3')\n",
    "avg_rest_hot_p.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75baf9c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "avg_rest_hot_p [avg_rest_hot_p ['Name'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f83593",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "avg_rest_hot_p = avg_rest_hot_p.dropna(subset=['Name'])\n",
    "# as the dataset contains both country name and country code, delete the merged columns\n",
    "avg_rest_hot_p = avg_rest_hot_p.drop(['Name', 'Iso3'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "184d8f2a",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Cuisine - Country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eecd9590",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "cuisine_temp = cuisine_rank.merge(country[['Name','Iso3']], how='left', left_on='Country', right_on='Name')\n",
    "cuisine_temp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "012c8cc7",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "cuisine_temp[cuisine_temp['Name'].isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bdf8000",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "As the United Kingdom was divided to England, Northern Ireland, Wales and Scotland,\n",
    "we will have one row for the United Kingdom with the average ratings of the 4 countries\n",
    "as we have the United Kingdom in the WEF datset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57cc6f9d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# add average of 4 nations in the United Kingdom to the existing row\n",
    "uk_rank = cuisine_rank.iloc[[28,68,79,87]]['Ratings'].mean()\n",
    "cuisine_rank.loc[len(cuisine_rank.index)] = ['United Kingdom', uk_rank]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c5c044b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Then sort by ratings, and reset index\n",
    "cuisine_rank.sort_values(by=['Ratings'], ignore_index=True, inplace=True, ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a0f621",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# merge again with modified data\n",
    "cuisine_rank = cuisine_rank.merge(country[['Name','Iso3']], how='left', left_on='Country', right_on='Name')\n",
    "# check UK\n",
    "cuisine_rank[cuisine_rank['Country']=='United Kingdom']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c96db998",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "cuisine_rank[cuisine_rank['Name'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07ec309",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "cuisine_rank = cuisine_rank.dropna(subset=['Name'])\n",
    "cuisine_rank = cuisine_rank.drop(['Name'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d322618",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### LGBT data - Country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf5647c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "lgbtq = lgbtq.merge(country[['Name', 'Iso3']], how='left', left_on='COUNTRY', right_on='Name')\n",
    "lgbtq.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76804355",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "lgbtq[lgbtq['Name'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f49d08",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "lgbtq=lgbtq.dropna(subset=['Name'])\n",
    "lgbtq = lgbtq.drop(['Name'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "id": "f5d32e44",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "country.to_csv('../cleaned_data/country.csv')\n",
    "\n",
    "pop.to_csv('../cleaned_data/population.csv')\n",
    "\n",
    "clim.to_csv('../cleaned_data/climate.csv')\n",
    "\n",
    "curr.to_csv('../cleaned_data/currencies.csv')\n",
    "\n",
    "lang.to_csv('../cleaned_data/language.csv')\n",
    "\n",
    "rel.to_csv('../cleaned_data/religion.csv')\n",
    "\n",
    "peace.to_csv('../cleaned_data/peace_index.csv')\n",
    "\n",
    "wef.to_csv('../cleaned_data/wef_ttdi.csv')\n",
    "\n",
    "avg_rest_hot_p.to_csv(\"../cleaned_data/avg_rest_hot_p.csv\")\n",
    "\n",
    "lgbtq.to_csv(\"../cleaned_data/lgbtq.csv\")\n",
    "\n",
    "cuisine_rank.to_csv('../cleaned_data/cuisine_rank.csv')\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a25b127",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}